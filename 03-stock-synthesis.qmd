# Running Stock Synthesis

## Model setup

1.  **Run the model without estimating anything at first.** The best way to do this is to run as `ss -stopph 0 -nohess` where `stopph` (short for "stop phase" is equivalent to setting the maximum phase in the starter file).

2.  **Make sure you pay attention to any notes or warnings in "warning.sso".** If you don't understand the warnings, find out, but don't just ignore it.

3.  **Debugging models that don't run**. The first place to look is "echoinput.sso". Start at the bottom and scan upwards until things start to look right or start at the top and scan downwards until things start to look wrong. It's often obvious when you have an extra input and things model starts to go awry. Use this information to fix your input files and try again. There are some additional debugging tips in the User Manual at https://nmfs-stock-synthesis.github.io/doc/SS330_User_Manual.html#debugging-tips. Consider also reading the input files into R using `r4ss::SS_read()` which may help you find mismatched columns or bad values in the inputs.

4.  **Once the model runs, look at the ".ss_new" files.** These files contain rich comments and often better formatting than your own input files. They are also good for debugging, because sometimes a model will run, but the parameter lines are associated with different fleets, or have different roles than you expected. Check the parameter names on the right hand side of "control.ss_new" to make sure everything looks right. You can then either replace your input files with the ".ss_new" files or just copy and paste elements that you want to keep. Note that if you've estimated any parameters, then the initial values in "control.ss_new" have been updated to these estimates.

5.  **Pull in parameter bounds that are way too wide** -- if you aren't anywhere near them during minimization, extremely wide bounds (like -15 to 15 on recruit deviations, or 3 to 31 for log-R0) just slow minimization and may result in poorer convergence properties.

## Model tuning

6. **Indices are typically tuned via the extra standard deviation parameter.** There are many reasons to expect that the input uncertainty values on indices of abundance are underestimates of the true uncertainty. Estimating an extra uncertainty parameter has worked well in a number of west coast groundfish assessments. However, the 2021 best practices document says, "STATs should be cautious to avoid adding variability to an index as a means of resolving model structure issues such as conflicts among data sources. Rather, variability should be added to account for sampling variance underestimating index uncertainty. *STATs should provide a priori reasons for why the index variability input to the model has been underestimated (or underspecified).*" Note that the extra SD parameter should reflect the observed variability in survey indices rather than poor fit to the observed trend in survey indices. Resist adding SD to surveys where there are trends in residuals without evidence of hyperdepletion or hyperstability, in which case a non-linear relationship between indices and stock size is more appropriate.

7. **Composition data is typically tuned by either iterative Francis weighting or estimating Dirichlet-multinomial parameters.** The McAllister-Ianelli method has not performed as well in simulation testing. See https://nmfs-stock-synthesis.github.io/doc/SS330_User_Manual.html#DataWeight for more info (Dirichlet-multinomial guidance was updated by Jim Thorson in September 2022).

8. **Discard ratios and mean body weight** These data SHOULD be tuned, but we don't typically do so. Kelli Johnson tuned these for Sablefish in 2019 with the following description:
> Added variances for discard rates and mean body weights were set using values calculated iteratively using the RMSE of differences between input and estimated values derived from SS3. Variances were parameterized in terms of standard deviation and coefficient of variation, respectively.

9. **Think about sigmaR.** This could be an arbitrarily chosen value, freely estimated, or iteratively tuned. Methot and Taylor (2011) suggest a way that the tuning could be done. Whatever you choose, put a little thought into it. SigmaR should be greater than the SD of the estimated recruitment deviations. The table `$sigma_R_info` output by `r4ss::SS_output()` provides information on tuning sigmaR.